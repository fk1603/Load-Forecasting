Index: Ali.py
IDEA additional info:
Subsystem: com.intellij.openapi.diff.impl.patch.BaseRevisionTextPatchEP
<+>#%matplotlib inline\r\nimport numpy as np\r\nimport pandas as pd\r\nimport matplotlib.pyplot as plt\r\nimport seaborn as sns\r\nimport os\r\nimport warnings\r\nwarnings.filterwarnings(\"ignore\")\r\nimport torch\r\ntorch.set_float32_matmul_precision('medium')\r\nfrom darts import TimeSeries, concatenate\r\nfrom darts.dataprocessing.transformers import Scaler\r\nfrom darts.models import TFTModel\r\nfrom darts.utils.timeseries_generation import datetime_attribute_timeseries\r\nfrom darts.utils.likelihood_models import QuantileRegression\r\nfrom pytorch_lightning.callbacks import Callback, EarlyStopping\r\nimport optuna\r\nfrom darts.metrics import mape, rmse, mse, mae, r2_score,smape\r\nfrom optuna.samplers import TPESampler\r\n\r\n\r\ndef add_time_lag_features(df, target_col, lag_periods):\r\n    for lag in lag_periods:\r\n        lagged_col_name = f\"{target_col}_lag{lag}\"\r\n        df[lagged_col_name] = df[target_col].shift(lag)\r\n\r\n    # Drop rows with NaN values introduced by lagging\r\n    df = df.dropna().reset_index(drop=True)\r\n    return df\r\n\r\npd.set_option(\"display.precision\",2)\r\nnp.set_printoptions(precision=2, suppress=True)\r\npd.options.display.float_format = '{:,.2f}'.format\r\n# load\r\ndf0 = pd.read_csv(\"processed_loadUTC_data.csv\", header=0, parse_dates=[\"Time (UTC)\"])\r\ndf0 = df0.rename(columns={\"Time (UTC)\": \"Timestamp\"})\r\ndf0.columns = [\"Timestamp\", \"Forecast\", \"Actual_Load\"]\r\n#df0 contains Timestamp and Actual Load Consumption\r\ndf0 = df0.drop(columns=[\"Forecast\"])  # Drop 'Forecast'\r\n\r\ndfw0 = pd.read_csv(\"weighted_avg_humidity.csv\", header=0, parse_dates=[\"Timestamp\"])\r\ndfw0.columns = [\"Timestamp\", \"Humidity\"]\r\ndfw1 = pd.read_csv(\"weighted_avg_solar.csv\", header=0, parse_dates=[\"Timestamp\"])\r\ndfw1.columns = [\"Timestamp\", \"Solar\"]\r\ndfw2 = pd.read_csv(\"weighted_avg_temp.csv\", header=0, parse_dates=[\"Timestamp\"])\r\ndfw2.columns = [\"Timestamp\", \"Temperature\"]\r\ndfw0 = dfw0.merge(dfw1, on=\"Timestamp\").merge(dfw2, on=\"Timestamp\")\r\n# Convert df0[\"Timestamp\"] to datetime by extracting the first timestamp\r\ndf0[\"Timestamp\"] = df0[\"Timestamp\"].str.extract(r\"(\\d{2}\\.\\d{2}\\.\\d{4} \\d{2}:\\d{2})\")[0]\r\ndf0[\"Timestamp\"] = pd.to_datetime(df0[\"Timestamp\"], format=\"%d.%m.%Y %H:%M\")\r\n# Ensure \"Actual\" is treated as a string\r\ndf0[\"Actual_Load\"] = df0[\"Actual_Load\"].astype(str).str.replace(\",\", \"\").astype(float)\r\n# Now merge\r\ndf_merged = df0.merge(dfw0, on=\"Timestamp\")\r\n# Remove rows between 2015 and 2020 (inclusive)\r\ndf_merged = df_merged[~df_merged[\"Timestamp\"].dt.year.between(2015, 2020)]\r\n\r\n# Example usage:\r\n# Assuming df_merged is the combined DataFrame with a 'Timestamp' index and 'Actual_Load' as the target\r\nlag_periods = [1, 2, 3, 24]  # Create lagged features for 1 hour, 2 hours, 3 hours, and 1 day\r\ndf_merged = add_time_lag_features(df_merged, target_col=\"Actual_Load\", lag_periods=lag_periods)\r\n\r\n# Print the first few rows to verify\r\nprint(df_merged.head())\r\n# Print the resulting DataFrame\r\nprint(df_merged)\r\n# backup of original sources\r\nimport holidays\r\nfrom pandas.tseries.offsets import CustomBusinessDay\r\n# Define Swedish holidays using the `holidays` package\r\nswe_holidays = holidays.Sweden(years=range(2021, 2025))\r\n# Create a CustomBusinessDay offset excluding Swedish holidays\r\nsweden_busday = CustomBusinessDay(holidays=swe_holidays.keys())\r\n# Create a date range for the entire period\r\ndate_range = pd.date_range(start='2021-01-01', end='2024-12-31', freq=sweden_busday)\r\n# Example DataFrame with a 'DateTime' column\r\n# Add Holiday column: 1 if date is a holiday, 0 otherwise\r\ndf_merged['Holiday'] = df_merged['Timestamp'].dt.date.apply(lambda x: 1 if x in swe_holidays else 0)\r\n# convert int and float64 columns to float32\r\nintcols = list(df_merged.dtypes[df_merged.dtypes == np.int64].index)\r\ndf_merged[intcols] = df_merged[intcols].applymap(np.float32)\r\n\r\n# 4. Pearson correlation: 'Actual' vs. each weather variable\r\ncorrelation_matrix = df_merged.corr(method=\"pearson\")\r\n# Show correlation of 'Actual' with others\r\nprint(correlation_matrix)\r\n# Plot heatmap\r\nnumerical_df = df_merged.drop(columns=[\"Timestamp\"])\r\n# Compute correlation matrix\r\ncorr = numerical_df.corr()\r\nplt.figure(figsize=(10, 8))\r\nsns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0, cbar_kws={'shrink': 0.75}, square=True)\r\nplt.grid(False)\r\nplt.title(\"Correlation Heatmap\")\r\n#plt.show()\r\n\r\n\r\n#create timeseries object for target variable i.e Actual_Load\r\n# Assuming 'Timestamp' column exists and represents the time\r\nts_P = TimeSeries.from_dataframe(df_merged, time_col=\"Timestamp\", value_cols=\"Actual_Load\")\r\n# check attributes of the time series\r\nprint(\"components:\", ts_P.components)                   # List of all component names (e.g. ['Actual_Load', 'Humidity', ...])\r\nprint(\"duration:\", ts_P.duration)                       # Total timedelta between first and last entry\r\nprint(\"frequency:\", ts_P.freq)                          # Pandas offset alias for frequency (e.g. <Minute>)\r\nprint(\"frequency:\", ts_P.freq_str)                      # String version of frequency (e.g. \"15min\", \"1H\")\r\nprint(\"has date time index?\", ts_P.has_datetime_index)  # True if the index is datetime-based\r\nprint(\"deterministic:\", ts_P.is_deterministic)          # True if the series is deterministic\r\nprint(\"univariate:\", ts_P.is_univariate)                # True if the series has only one component\r\n# create time series object for the feature columns\r\n# Set the Timestamp as the index\r\ndf_covF = df_merged.loc[:, df_merged.columns != \"Actual_Load\"]\r\ndf_covF.set_index('Timestamp', inplace=True)\r\n\r\n# Now, create the time series for feature columns\r\nts_covF = TimeSeries.from_dataframe(df_covF)\r\n\r\n# Check the attributes\r\nprint(\"components (columns) of feature time series:\", ts_covF.components)\r\nprint(\"duration:\", ts_covF.duration)\r\nprint(\"frequency:\", ts_covF.freq)\r\nprint(\"frequency:\", ts_covF.freq_str)\r\nprint(\"has date time index? (or else, it must have an integer index):\", ts_covF.has_datetime_index)\r\nprint(\"deterministic:\", ts_covF.is_deterministic)\r\nprint(\"univariate:\", ts_covF.is_univariate)\r\n\r\n# example: operating with time series objects:\r\n# we can also create a 3-dimensional numpy array from a time series object\r\n# 3 dimensions: time (rows) / components (columns) / samples\r\nar_covF = ts_covF.all_values()\r\nprint(type(ar_covF))\r\n\r\n# example: operating with time series objects:\r\n# we can also create a pandas series or dataframe from a time series object\r\ndf_covF = ts_covF.to_dataframe()\r\ntype(df_covF)\r\n\r\nSPLIT_TRAIN = 0.5\r\nSPLIT_VAL = 0.25\r\nSPLIT_TEST = 0.25\r\n# Calculate indices for splitting\r\ntrain_idx = int(len(ts_P) * SPLIT_TRAIN)\r\nval_idx = int(len(ts_P) * (SPLIT_TRAIN + SPLIT_VAL))\r\n\r\n# Train/val/test split\r\nts_train = ts_P[:train_idx]\r\nts_val = ts_P[train_idx:val_idx]\r\nts_test = ts_P[val_idx:]\r\n\r\nprint(\"training start:\", ts_train.start_time())\r\nprint(\"training end:\", ts_train.end_time())\r\nprint(\"training duration:\",ts_train.duration)\r\nprint(\"Validation start:\", ts_val.start_time())\r\nprint(\"Validation end:\", ts_val.end_time())\r\nprint(\"Validation duration:\", ts_val.duration)\r\nprint(\"test start:\", ts_test.start_time())\r\nprint(\"test end:\", ts_test.end_time())\r\nprint(\"test duration:\", ts_test.duration)\r\n\r\n\r\nscalerP = Scaler()\r\nscalerP.fit(ts_train)\r\nts_ttrain = scalerP.transform(ts_train)\r\nts_tval = scalerP.transform(ts_val)\r\nts_ttest = scalerP.transform(ts_test)\r\nts_t = ts_P\r\n\r\n# make sure data are of type float\r\nts_t = ts_t.astype(\"float32\")\r\nts_ttrain = ts_ttrain.astype(\"float32\")\r\nts_tval = ts_tval.astype(\"float32\")\r\nts_ttest = ts_ttest.astype(\"float32\")\r\n\r\n# Calculate indices for splitting\r\ntrain_idx = int(len(ts_covF) * SPLIT_TRAIN)\r\nval_idx = int(len(ts_covF) * (SPLIT_TRAIN + SPLIT_VAL))\r\n\r\n# Train/val/test split for feature covariates\r\ncovF_train = ts_covF[:train_idx]\r\ncovF_val = ts_covF[train_idx:val_idx]\r\ncovF_test = ts_covF[val_idx:]\r\n\r\n# Scale feature covariates\r\nscalerF = Scaler()\r\nscalerF.fit_transform(covF_train)\r\ncovF_ttrain = scalerF.transform(covF_train)\r\ncovF_tval = scalerF.transform(covF_val)\r\ncovF_ttest = scalerF.transform(covF_test)\r\ncovF_t = scalerF.transform(ts_covF)\r\n\r\n# Make sure data are of type float\r\ncovF_ttrain = covF_ttrain.astype(np.float32)\r\ncovF_tval = covF_tval.astype(np.float32)\r\ncovF_ttest = covF_ttest.astype(np.float32)\r\n\r\npd.options.display.float_format = '{:.2f}'.format\r\nprint(\"first and last row of scaled feature covariates:\")\r\n\r\n# Feature engineering - create time covariates: hour, weekday, month, year, country-specific holidays\r\ncovT = datetime_attribute_timeseries(ts_P.time_index, attribute=\"hour\")\r\ncovT = covT.stack(datetime_attribute_timeseries(covT.time_index, attribute=\"day_of_week\"))\r\ncovT = covT.stack(datetime_attribute_timeseries(covT.time_index, attribute=\"month\"))\r\ncovT = covT.stack(datetime_attribute_timeseries(covT.time_index, attribute=\"year\"))\r\n\r\n# Train/val/test split for time covariates\r\ncovT_train = covT[:train_idx]\r\ncovT_val = covT[train_idx:val_idx]\r\ncovT_test = covT[val_idx:]\r\n\r\ncovT_val_extended = covT_val.to_dataframe()\r\nadditional_time_index = pd.date_range(start=covT_val_extended.index[-1] + pd.Timedelta(hours=1),\r\n                                      periods=48, freq='H')\r\nadditional_rows = pd.DataFrame(index=additional_time_index, columns=covT_val_extended.columns)\r\ncovT_val_extended = pd.concat([covT_val_extended, additional_rows], ignore_index=False)\r\ncovT_val_extended = TimeSeries.from_dataframe(covT_val_extended)\r\n\r\n# Rescale the covariates: fitting on the training set\r\nscalerT = Scaler()\r\nscalerT.fit(covT_train)\r\ncovT_ttrain = scalerT.transform(covT_train)\r\ncovT_tval = scalerT.transform(covT_val)  # Scale before extending\r\ncovT_ttest = scalerT.transform(covT_test)\r\ncovT_t = scalerT.transform(covT)\r\n\r\ncovT_t = covT_t.astype(np.float32)\r\ncovT_ttrain = covT_ttrain.astype(np.float32)\r\ncovT_tval = covT_tval.astype(np.float32)\r\ncovT_ttest = covT_ttest.astype(np.float32)\r\n\r\npd.options.display.float_format = '{:.0f}'.format\r\nprint(\"first and last row of unscaled time covariates:\")\r\n\r\n# Combine feature and time covariates along component dimension: axis=1\r\nts_cov = ts_covF.concatenate(covT.slice_intersect(ts_covF), axis=1)  # unscaled F+T\r\ncov_t = covF_t.concatenate(covT_t.slice_intersect(covF_t), axis=1)  # scaled F+T\r\ncov_ttrain = covF_ttrain.concatenate(covT_ttrain.slice_intersect(covF_ttrain), axis=1)  # scaled F+T training set\r\ncov_tval = covF_tval.concatenate(covT_tval.slice_intersect(covF_tval), axis=1)  # scaled F+T validation set\r\ncov_ttest = covF_ttest.concatenate(covT_ttest.slice_intersect(covF_ttest), axis=1)  # scaled F+T test set\r\n\r\npd.options.display.float_format = '{:.2f}'.format\r\nprint(\"first and last row of unscaled covariates:\")\r\n\r\nprint(\"covF_ttrain start:\", covF_ttrain.start_time())\r\nprint(\"covF_ttrain end:\", covF_ttrain.end_time())\r\nprint(\"covF_tval start:\", covF_tval.start_time())\r\nprint(\"covF_tval end:\", covF_tval.end_time())\r\nprint(\"covF_ttest start:\", covF_ttest.start_time())\r\nprint(\"covF_ttest end:\", covF_ttest.end_time())\r\n\r\nprint(\"covT_ttrain start:\", covT_ttrain.start_time())\r\nprint(\"covT_ttrain end:\", covT_ttrain.end_time())\r\nprint(\"covT_tval start:\", covT_tval.start_time())\r\nprint(\"covT_tval end:\", covT_tval.end_time())\r\nprint(\"covT_ttest start:\", covT_ttest.start_time())\r\nprint(\"covT_ttest end:\", covT_ttest.end_time())\r\n\r\nLOAD = True# True = load previously saved model from disk? False = (re)train the model\r\n\r\nSAVE = \"_TFT_model_single_step.pt\"  # file name to save the model under\r\nmpath = r'c:\\\\Users\\\\Ali Kamran\\\\Downloads\\\\model' + SAVE  # file path where the model will be saved or loaded from\r\n\r\n\r\ndef build_fit_tft_model(\r\n        input_chunk_length,\r\n        output_chunk_length,\r\n        hidden_size,\r\n        lstm_layers,\r\n        num_attention_heads,\r\n        dropout,\r\n        lr,\r\n        callbacks=None,\r\n\r\n):\r\n    # reproducibility\r\n    torch.manual_seed(42)\r\n\r\n    batch_size = 256\r\n    n_epochs = 70\r\n    nr_epochs_val_period = 1\r\n    QUANTILES = [\r\n        0.01,\r\n        0.05,\r\n        0.1,\r\n        0.15,\r\n        0.2,\r\n        0.25,\r\n        0.3,\r\n        0.4,\r\n        0.5,\r\n        0.6,\r\n        0.7,\r\n        0.75,\r\n        0.8,\r\n        0.85,\r\n        0.9,\r\n        0.95,\r\n        0.99,\r\n    ]\r\n\r\n    # Monitor validation loss for early stopping\r\n    early_stopper = EarlyStopping(\"val_loss\", min_delta=0.005, patience=3, verbose=True)\r\n    if callbacks is None:\r\n        callbacks = [early_stopper]\r\n    else:\r\n        callbacks = [early_stopper] + callbacks\r\n\r\n    # detect if a GPU is available\r\n    if torch.cuda.is_available():\r\n        pl_trainer_kwargs = {\r\n            \"accelerator\": \"gpu\",\r\n            \"callbacks\": callbacks,\r\n        }\r\n        num_workers = 4\r\n    else:\r\n        pl_trainer_kwargs = {\"callbacks\": callbacks}\r\n        num_workers = 0\r\n\r\n    # Build the TFT model\r\n    model = TFTModel(\r\n        input_chunk_length=input_chunk_length,\r\n        output_chunk_length=output_chunk_length,\r\n        hidden_size=hidden_size,\r\n        lstm_layers=lstm_layers,\r\n        num_attention_heads=num_attention_heads,\r\n        dropout=dropout,\r\n        optimizer_kwargs={\"lr\": lr},\r\n        batch_size=batch_size,\r\n        n_epochs=n_epochs,\r\n        nr_epochs_val_period=nr_epochs_val_period,\r\n        likelihood=QuantileRegression(QUANTILES),\r\n        model_name=\"tft_model_1h\",\r\n        log_tensorboard=True,\r\n        force_reset=True,\r\n        save_checkpoints=True,\r\n        pl_trainer_kwargs=pl_trainer_kwargs,\r\n    )\r\n\r\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\r\n    print(f\"Model is using device: {device}\")\r\n\r\n    # Train the model\r\n    # Ensure all inputs are float32\r\n    model.fit(\r\n        series=ts_ttrain.astype(np.float32),\r\n        future_covariates=cov_t.astype(np.float32),\r\n        val_series=ts_tval.astype(np.float32),\r\n        val_future_covariates=cov_t.astype(np.float32),\r\n        verbose=True,\r\n    )\r\n\r\n    return model\r\nQUANTILES =[\r\n    0.01,\r\n    0.05,\r\n    0.1,\r\n    0.15,\r\n    0.2,\r\n    0.25,\r\n    0.3,\r\n    0.4,\r\n    0.5,\r\n    0.6,\r\n    0.7,\r\n    0.75,\r\n    0.8,\r\n    0.85,\r\n    0.9,\r\n    0.95,\r\n    0.99,\r\n]\r\n\r\nfrom optuna.integration import PyTorchLightningPruningCallback\r\nfrom pytorch_lightning import Callback\r\n\r\nclass CustomPyTorchLightningPruningCallback(Callback):\r\n    def __init__(self, trial, monitor=\"val_loss\"):\r\n        self._trial = trial\r\n        self._monitor = monitor\r\n\r\n    def on_validation_end(self, trainer, pl_module):\r\n        logs = trainer.callback_metrics\r\n        current_score = logs.get(self._monitor)\r\n        if current_score is None:\r\n            return\r\n        self._trial.report(current_score, step=trainer.global_step)\r\n        if self._trial.should_prune():\r\n            message = f\"Trial was pruned at step {trainer.global_step}.\"\r\n            raise optuna.TrialPruned(message)\r\n\r\ndef objective(trial):\r\n    callback = [CustomPyTorchLightningPruningCallback(trial, monitor=\"val_loss\")]\r\n\r\n    input_chunk_length = trial.suggest_categorical(\"input_chunk_length\", [12, 24, 48])\r\n    hidden_size = trial.suggest_categorical(\"hidden_size\", [12, 24, 32])\r\n    lstm_layers = trial.suggest_int(\"lstm_layers\", 1, 4)\r\n    num_attention_heads = trial.suggest_int(\"num_attention_heads\", 2, 6)\r\n    lr = trial.suggest_float(\"lr\", 1e-4, 1e-2, log = True)\r\n    dropout = trial.suggest_float(\"dropout\", 0.1, 0.5)\r\n\r\n    # build and train the TFT model with these hyper-parameters:\r\n    tft_model = build_fit_tft_model(\r\n        input_chunk_length=input_chunk_length,\r\n        output_chunk_length = 24,\r\n        hidden_size=hidden_size,\r\n        lstm_layers=lstm_layers,\r\n        num_attention_heads=num_attention_heads,\r\n        lr=lr,\r\n        dropout=dropout,\r\n        callbacks=callback\r\n    )\r\n\r\n\r\n    # Evaluate how good it is on the validation set\r\n    #In the next trial, increase the num_samples MAPE is signifantly dependant on n_samples\r\n    preds = tft_model.predict(n=len(ts_tval), num_samples=1, n_jobs=os.cpu_count(), verbose=True)\r\n    print('0 Ali')\r\n    error = mape(preds, ts_tval)\r\n\r\n    return error if error != np.nan else float(\"inf\")\r\ndef print_callback(study, trial):\r\n    print(f\"Current value: {trial.value}, Current params: {trial.params}\")\r\n    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")\r\n\r\n# Ali.py\r\nfrom sklearn.feature_selection import RFE\r\nfrom sklearn.model_selection import train_test_split\r\nfrom sklearn.preprocessing import StandardScaler\r\nfrom lightgbm import LGBMRegressor\r\n\r\n# Select the target column\r\ntarget_col = 'Actual_Load'\r\ndf2_1 = df_merged.copy()\r\n\r\ndf2_numeric = df_merged.select_dtypes(include=[np.number])  # This includes only numeric columns\r\n\r\n# Convert target column to numeric if it's not already\r\ndf_merged[target_col] = pd.to_numeric(df_merged[target_col], errors='coerce')\r\n\r\n# Prepare the features and target data\r\nX = df2_numeric.drop(columns=[target_col])\r\ny = df2_numeric[target_col]\r\n\r\n# Split the data into train and test sets\r\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\r\n\r\n# Standardize the features\r\nscaler = StandardScaler()\r\nX_train_scaled = scaler.fit_transform(X_train)\r\nX_test_scaled = scaler.transform(X_test)\r\n\r\n# Create the LGBMRegressor model\r\nlgbm_model = LGBMRegressor()\r\n\r\n# Perform RFE using the LGBMRegressor model\r\nrfe = RFE(estimator=lgbm_model, n_features_to_select=8, step=1)\r\nrfe.fit(X_train_scaled, y_train)\r\n\r\n# Get the selected features\r\nselected_features = X.columns[rfe.support_]\r\n\r\n# Print the selected features\r\nprint(\"Selected features:\")\r\nprint(selected_features)\r\n\r\n# Create a new dataframe with the selected features and target\r\nselected_df = df2_numeric[selected_features.to_list() + [target_col]]\r\n\r\n# Train and SAVE the TFT model using the best hyperparameters found by Optuna\r\nsampler = TPESampler(seed=42)  # Define sampler here\r\n\r\nif LOAD:\r\n    try:\r\n        print(\"have loaded a previously saved model from disk:\" + mpath)\r\n        best_model = TFTModel.load(mpath)\r\n        # Add code here to evaluate or use the loaded model if needed\r\n    except FileNotFoundError:\r\n        print(f\"Warning: Model not found at {mpath}. Training a new model using best Optuna parameters.\")\r\n        study = optuna.create_study(study_name=\"T15\", storage=\"sqlite:///optimization.db\", load_if_exists=True,\r\n                                    sampler=sampler, direction=\"minimize\")\r\n        best_params = study.best_trial.params\r\n        best_model = build_fit_tft_model(\r\n            input_chunk_length=best_params['input_chunk_length'],\r\n            output_chunk_length=1,\r\n            hidden_size=best_params['hidden_size'],\r\n            lstm_layers=best_params['lstm_layers'],\r\n            num_attention_heads=best_params['num_attention_heads'],\r\n            lr=best_params['lr'],\r\n            dropout=best_params['dropout'],\r\n        )\r\n        print(\"have saved the best model after training with Optuna's best hyperparameters:\", mpath)\r\n        best_model.save(mpath)\r\n    except Exception as e:\r\n        print(f\"Error loading model: {e}\")\r\n        # Handle other potential loading errors\r\nelse:\r\n    # Code to run if LOAD is False (force retraining with Optuna)\r\n    sampler = TPESampler(seed=42)\r\n    study = optuna.create_study(study_name=\"T15\", storage=\"sqlite:///optimization.db\", load_if_exists=True, sampler=sampler, direction=\"minimize\")\r\n    study.optimize(objective, n_trials=50, callbacks=[print_callback])\r\n    print(f\"Best value: {study.best_value}, Best params: {study.best_trial.params}\")\r\n    best_params = study.best_trial.params\r\n    best_model = build_fit_tft_model(\r\n        input_chunk_length=best_params['input_chunk_length'],\r\n        output_chunk_length=24,\r\n        hidden_size=best_params['hidden_size'],\r\n        lstm_layers=best_params['lstm_layers'],\r\n        num_attention_heads=best_params['num_attention_heads'],\r\n        lr=best_params['lr'],\r\n        dropout=best_params['dropout'],\r\n    )\r\n    print(\"have saved the best model after training with Optuna's best hyperparameters:\", mpath)\r\n    best_model.save(mpath)\r\n\r\n\r\n# Try a reduced number of samples for faster evaluation\r\nnum_eval_samples = 500  # Adjust this number as needed\r\n\r\n# Experiment with the number of parallel jobs\r\nn_prediction_jobs = os.cpu_count()  # Or try a slightly smaller value\r\n\r\ntft_predictions = best_model.predict(\r\n    n=len(ts_tval),\r\n    num_samples=num_eval_samples,\r\n    n_jobs=n_prediction_jobs,\r\n    verbose=True\r\n)\r\nerror = mape(tft_predictions, ts_tval)\r\nprint(error)\r\n# retrieve forecast series for chosen quantiles,\r\n# inverse-transform each series,\r\n# insert them as columns in a new dataframe dfY\r\nq50_RMSE = np.inf\r\nq50_MAPE = np.inf\r\nts_q50 = None\r\npd.options.display.float_format = '{:,.2f}'.format\r\ndfY_tft = pd.DataFrame()\r\ndfY_tft[\"Actual\"] = TimeSeries.to_series(ts_val)\r\n\r\n\r\n# helper function: get forecast values for selected quantile q and insert them in dataframe dfY\r\ndef predQ(ts_t, q):\r\n    ts_tq = ts_t.quantile_timeseries(q)\r\n    ts_q = scalerP.inverse_transform(ts_tq)\r\n    s = TimeSeries.to_series(ts_q)\r\n    header = \"Q\" + format(int(q * 100), \"02d\")\r\n    dfY_tft[header] = s\r\n    if q == 0.5:\r\n        ts_q50 = ts_q\r\n        q50_RMSE = rmse(ts_q50, ts_val)\r\n        q50_MAPE = mape(ts_q50, ts_val)\r\n        print(\"RMSE:\", f'{q50_RMSE:.2f}')\r\n        print(\"MAPE:\", f'{q50_MAPE:.2f}')\r\n\r\n\r\n# call helper function predQ, once for every quantile\r\n_ = [predQ(tft_predictions, q) for q in QUANTILES]\r\n\r\n# move Q50 column to the left of the Actual column\r\ncol = dfY_tft.pop(\"Q50\")\r\ndfY_tft.insert(1, col.name, col)\r\n\r\ndfY_tft.to_csv('result_TFT_1h_val.csv')\r\nimport plotly.graph_objs as go\r\n\r\ndef plot_actual_vs_q50(df):\r\n    fig = go.Figure()\r\n\r\n    fig.add_trace(go.Scatter(x=df.index, y=df['Actual'], mode='lines', name='Actual'))\r\n    fig.add_trace(go.Scatter(x=df.index, y=df['Q50'], mode='lines', name='Q50'))\r\n\r\n    fig.update_layout(title='Actual vs Q50 Load Data (Validation set)', xaxis_title='DateTime', yaxis_title='Load Value')\r\n\r\n    fig.show()\r\n\r\n\r\n# Plot the actual vs Q50 values\r\nplot_actual_vs_q50(dfY_tft)\r\n\r\n# Make predictions on the unseen test data\r\nbest_tft_test = best_model.predict(\r\n    series=ts_ttrain.astype(np.float32).concatenate(ts_tval.astype(np.float32)),\r\n    future_covariates=cov_t.astype(np.float32),\r\n    n= len(ts_ttest)+24,\r\n    num_samples=num_eval_samples,\r\n    n_jobs=3,\r\n    verbose=True\r\n)\r\n\r\n\r\ntft_mape = mape(scalerP.inverse_transform(best_tft_test), ts_test)\r\ntft_rmse = rmse(scalerP.inverse_transform(best_tft_test), ts_test)\r\ntft_mse = mse(scalerP.inverse_transform(best_tft_test), ts_test)\r\ntft_r2 = r2_score(scalerP.inverse_transform(best_tft_test), ts_test)\r\ntft_smape = smape(scalerP.inverse_transform(best_tft_test), ts_test)\r\ntft_mae = mae(scalerP.inverse_transform(best_tft_test), ts_test)\r\n\r\nq50_RMSE = np.inf\r\nq50_MAPE = np.inf\r\nts_q50 = None\r\npd.options.display.float_format = '{:,.2f}'.format\r\ndfY_tft1 = pd.DataFrame()\r\ndfY_tft1[\"Actual\"] = TimeSeries.to_series(ts_test)\r\n\r\n\r\ndef predQ(ts_t, q):\r\n    ts_tq = ts_t.quantile_timeseries(q)\r\n    ts_q = scalerP.inverse_transform(ts_tq)\r\n    s = TimeSeries.to_series(ts_q)\r\n    header = \"Q\" + format(int(q * 100), \"02d\")\r\n    dfY_tft1[header] = s\r\n    if q == 0.5:\r\n        ts_q50 = ts_q\r\n        q50_RMSE = rmse(ts_q50, ts_test)\r\n        q50_MAPE = mape(ts_q50, ts_test)\r\n        print(\"RMSE:\", f'{q50_RMSE:.2f}')\r\n        print(\"MAPE:\", f'{q50_MAPE:.2f}')\r\n\r\n\r\n# call helper function predQ, once for every quantile\r\n_ = [predQ(best_tft_test, q) for q in QUANTILES]\r\n\r\n# move Q50 column to the left of the Actual column\r\ncol = dfY_tft1.pop(\"Q50\")\r\ndfY_tft1.insert(1, col.name, col)\r\n\r\nimport plotly.graph_objs as go\r\n\r\ndef plot_actual_vs_q50(df):\r\n    fig = go.Figure()\r\n\r\n    fig.add_trace(go.Scatter(x=df.index, y=df['Actual'], mode='lines', name='Actual'))\r\n    fig.add_trace(go.Scatter(x=df.index, y=df['Q50'], mode='lines', name='Q50'))\r\n\r\n    fig.update_layout(title='Actual vs Q50 Load Data (Test Set)', xaxis_title='DateTime', yaxis_title='Load Value')\r\n\r\n    fig.show()\r\n\r\n\r\n# Plot the actual vs Q50 values\r\nplot_actual_vs_q50(dfY_tft1)\r\n\r\n\r\ndfY_tft1.to_csv('result_TFT_1h.csv')\r\n\r\nimport matplotlib.pyplot as plt\r\n\r\n# Prepare the data\r\nn_points = len(dfY_tft1)\r\nactual_data = dfY_tft1[\"Actual\"][-n_points:]\r\nq50_data = dfY_tft1[\"Q50\"][-n_points:]\r\n\r\n# Plot the actual data and Q50 predictions\r\nplt.figure(figsize=(14, 6))\r\nplt.plot(actual_data, label=\"Actual\", color=\"red\")\r\nplt.plot(q50_data, label=\"Q50\", color=\"blue\")\r\n\r\n# Plot the confidence intervals (quantiles) as shaded areas\r\nfor i, (q1, q2) in enumerate([(0.01, 0.95), (0.1, 0.9)]):\r\n    col1 = f\"Q{int(q1 * 100):02d}\"\r\n    col2 = f\"Q{int(q2 * 100):02d}\"\r\n    plt.fill_between(\r\n        dfY_tft1.index[-n_points:],\r\n        dfY_tft1[col1][-n_points:],\r\n        dfY_tft1[col2][-n_points:],\r\n        color=\"blue\",\r\n        alpha=0.1 * (i + 1),\r\n        label=f\"{int(q1 * 100)}-{int(q2 * 100)}% CI\",\r\n    )\r\n\r\n# Customize the plot\r\nplt.xlabel(\"Time\")\r\nplt.ylabel(\"Demand (MW)\")\r\nplt.title(\"Probabilistic Forecast\")\r\nplt.legend()\r\nplt.show()\r\n\r\nimport plotly.graph_objects as go\r\n\r\nfig = go.Figure()\r\n\r\n# Add actual data\r\nfig.add_trace(go.Scatter(\r\n    x=dfY_tft1.index[-n_points:], y=actual_data,\r\n    mode=\"lines\", name=\"Actual\", line=dict(color=\"red\")\r\n))\r\n\r\n# Add Q50 predictions\r\nfig.add_trace(go.Scatter(\r\n    x=dfY_tft1.index[-n_points:], y=q50_data,\r\n    mode=\"lines\", name=\"Q50\", line=dict(color=\"blue\")\r\n))\r\n\r\n# Add confidence intervals\r\nfor i, (q1, q2) in enumerate([(0.01, 0.95), (0.1, 0.9)]):\r\n    col1 = f\"Q{int(q1 * 100):02d}\"\r\n    col2 = f\"Q{int(q2 * 100):02d}\"\r\n    fig.add_trace(go.Scatter(\r\n        x=dfY_tft1.index[-n_points:], y=dfY_tft1[col2][-n_points:],\r\n        mode='lines', line=dict(width=0), showlegend=False\r\n    ))\r\n    fig.add_trace(go.Scatter(\r\n        x=dfY_tft1.index[-n_points:], y=dfY_tft1[col1][-n_points:],\r\n        fill='tonexty',\r\n        fillcolor=f'rgba(0,0,255,{0.1 * (i + 1)})',\r\n        mode='lines', line=dict(width=0),\r\n        name=f\"{int(q1 * 100)}â€“{int(q2 * 100)}% CI\"\r\n    ))\r\n\r\n# Customize layout\r\nfig.update_layout(\r\n    title=\"Probabilistic Forecast\",\r\n    xaxis_title=\"Time\",\r\n    yaxis_title=\"Demand (MW)\",\r\n    legend=dict(x=0.01, y=0.99),\r\n    template=\"plotly_white\"\r\n)\r\n\r\n# Show full screen in browser\r\nfig.show(config={\"responsive\": True})\r\n\r\n
Subsystem: com.intellij.openapi.diff.impl.patch.CharsetEP
<+>UTF-8
===================================================================
diff --git a/Ali.py b/Ali.py
--- a/Ali.py	(revision 94ae58e94092f6e97ed6cdd7f4ff8e7e8935a9da)
+++ b/Ali.py	(date 1746704951499)
@@ -1,4 +1,3 @@
-#%matplotlib inline
 import numpy as np
 import pandas as pd
 import matplotlib.pyplot as plt
@@ -8,7 +7,7 @@
 warnings.filterwarnings("ignore")
 import torch
 torch.set_float32_matmul_precision('medium')
-from darts import TimeSeries, concatenate
+from darts import TimeSeries
 from darts.dataprocessing.transformers import Scaler
 from darts.models import TFTModel
 from darts.utils.timeseries_generation import datetime_attribute_timeseries
@@ -17,7 +16,8 @@
 import optuna
 from darts.metrics import mape, rmse, mse, mae, r2_score,smape
 from optuna.samplers import TPESampler
-
+import darts
+torch.serialization.safe_globals([darts.utils.likelihood_models.QuantileRegression])
 
 def add_time_lag_features(df, target_col, lag_periods):
     for lag in lag_periods:
@@ -471,6 +471,7 @@
     try:
         print("have loaded a previously saved model from disk:" + mpath)
         best_model = TFTModel.load(mpath)
+
         # Add code here to evaluate or use the loaded model if needed
     except FileNotFoundError:
         print(f"Warning: Model not found at {mpath}. Training a new model using best Optuna parameters.")
@@ -518,7 +519,7 @@
 n_prediction_jobs = os.cpu_count()  # Or try a slightly smaller value
 
 tft_predictions = best_model.predict(
-    n=len(ts_tval),
+    n=24,
     num_samples=num_eval_samples,
     n_jobs=n_prediction_jobs,
     verbose=True
@@ -579,7 +580,7 @@
 best_tft_test = best_model.predict(
     series=ts_ttrain.astype(np.float32).concatenate(ts_tval.astype(np.float32)),
     future_covariates=cov_t.astype(np.float32),
-    n= len(ts_ttest)+24,
+    n= len(24),
     num_samples=num_eval_samples,
     n_jobs=3,
     verbose=True
